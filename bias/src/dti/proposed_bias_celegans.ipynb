{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdMolDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rdic = ['A','I','L','V','F','W','Y','N','C','Q','M','S','T','D','E','R','H','K','G','P','O','U','X','B','Z']\n",
    "seq_dic = {w: i+1 for i, w in enumerate(seq_rdic)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeSeq(seq, seq_dic):\n",
    "    if pd.isnull(seq):\n",
    "        return [0]\n",
    "    else:\n",
    "        return [seq_dic[aa] for aa in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_seq(x, max_len=2500):\n",
    "    if len(x) == 0:\n",
    "        return x\n",
    "    elif len(x) >= max_len:\n",
    "        return x[:max_len]\n",
    "    else:\n",
    "        return x + [0]*(max_len-len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(dti_dir, prot_len=2500, drug_len=2048, is_train=True):\n",
    "\n",
    "    protein_col = \"protein\"\n",
    "    drug_col = \"compound\"\n",
    "    label_col = \"label\"\n",
    "    weight_col = \"weight\"\n",
    "    col_names = [protein_col, drug_col, label_col, weight_col]\n",
    "    \n",
    "    dti_df = pd.read_csv(dti_dir, header=0)\n",
    "\n",
    "    dti_df[protein_col] = dti_df[protein_col].map(lambda a: encodeSeq(a, seq_dic))\n",
    "    \n",
    "    drug_feature = np.stack(dti_df[drug_col].map(\n",
    "        lambda sm: AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(sm),2,nBits=drug_len)\n",
    "    ))\n",
    "    \n",
    "    protein_feature = np.stack(dti_df[protein_col].map(padding_seq))\n",
    "    label = dti_df[label_col].values\n",
    "    if is_train:\n",
    "        weight = dti_df[weight_col].values\n",
    "    \n",
    "    print(\"\\tPositive data : %d\" %(sum(dti_df[label_col])))\n",
    "    print(\"\\tNegative data : %d\" %(dti_df.shape[0] - sum(dti_df[label_col])))\n",
    "    \n",
    "    if is_train:\n",
    "        return {\"protein_feature\": protein_feature, \n",
    "            \"drug_feature\": drug_feature, \n",
    "            \"label\": label,\n",
    "            \"weight\": weight,\n",
    "            }\n",
    "    else:\n",
    "        return {\"protein_feature\": protein_feature, \n",
    "            \"drug_feature\": drug_feature, \n",
    "            \"label\": label,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:00:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:00:14] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPositive data : 2000\n",
      "\tNegative data : 1949\n",
      "\tPositive data : 401\n",
      "\tNegative data : 377\n"
     ]
    }
   ],
   "source": [
    "train_datas = parse_data(\"../../data/maked/bias/train_celegans.csv\")\n",
    "test_datas = parse_data(\"../../data/maked/bias/test_celegans.csv\", is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_drug = nn.Linear(2048, 64)\n",
    "        \n",
    "        self.conv1D = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=128, stride=1, padding=0)\n",
    "        self.batch = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, 128)\n",
    "        self.fc_interaction = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, drug, protein):\n",
    "        compound_vector = self.fc_drug(drug)\n",
    "        compound_vector = torch.relu(compound_vector)\n",
    "\n",
    "        protein = torch.unsqueeze(protein, 1)\n",
    "        protein_vector = self.conv1D(protein)\n",
    "        protein_vector = self.batch(protein_vector)\n",
    "        protein_vector = torch.relu(protein_vector)\n",
    "        \n",
    "        protein_vector = F.max_pool1d(protein_vector, kernel_size=2373)\n",
    "        protein_vector = torch.squeeze(protein_vector, 2)\n",
    "        \n",
    "        cat_vector = torch.cat((compound_vector, protein_vector), 1)\n",
    "        \n",
    "        for j in range(2):\n",
    "            cat_vector = torch.relu(self.fc_out(cat_vector))\n",
    "        out = self.fc_interaction(cat_vector)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses GPU...\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drug_dataset = torch.FloatTensor(train_datas[\"drug_feature\"])\n",
    "train_protein_dataset = torch.FloatTensor(train_datas[\"protein_feature\"])\n",
    "train_weight_dataset = torch.FloatTensor(train_datas[\"weight\"])\n",
    "train_target_dataset = torch.LongTensor(train_datas[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drug_dataset = torch.FloatTensor(test_datas[\"drug_feature\"])\n",
    "test_protein_dataset = torch.FloatTensor(test_datas[\"protein_feature\"])\n",
    "test_target_dataset = torch.LongTensor(test_datas[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_drug_dataset, train_protein_dataset, train_weight_dataset, train_target_dataset)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_drug_dataset, test_protein_dataset, test_target_dataset)\n",
    "\n",
    "N = len(train_dataset)\n",
    "train_size = int(0.8 * N)\n",
    "val_size = N - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 68.1805129647255, AUC: 0.6529832537114091\n",
      "epoch: 1, loss: 67.67079412937164, AUC: 0.6763946678995222\n",
      "epoch: 2, loss: 66.34617406129837, AUC: 0.6967303642060924\n",
      "epoch: 3, loss: 64.98169642686844, AUC: 0.7162024194791184\n",
      "epoch: 4, loss: 63.827765345573425, AUC: 0.7381209225869421\n",
      "epoch: 5, loss: 62.479497253894806, AUC: 0.7539297272306982\n",
      "epoch: 6, loss: 60.3669136762619, AUC: 0.7716777109980993\n",
      "epoch: 7, loss: 58.74269127845764, AUC: 0.7864077669902912\n",
      "epoch: 8, loss: 57.180183589458466, AUC: 0.7970668310474135\n",
      "epoch: 9, loss: 54.302863001823425, AUC: 0.8075653670313865\n",
      "epoch: 10, loss: 53.19386637210846, AUC: 0.8219229978938717\n",
      "epoch: 11, loss: 51.370805501937866, AUC: 0.8311052036780191\n",
      "epoch: 12, loss: 48.71482867002487, AUC: 0.8410836287049879\n",
      "epoch: 13, loss: 47.22610658407211, AUC: 0.849527405352648\n",
      "epoch: 14, loss: 46.749104380607605, AUC: 0.8601222581805106\n",
      "epoch: 15, loss: 45.11350464820862, AUC: 0.8629732367596444\n",
      "epoch: 16, loss: 43.529558420181274, AUC: 0.8732149278265784\n",
      "epoch: 17, loss: 42.432594299316406, AUC: 0.8759310628242667\n",
      "epoch: 18, loss: 41.57430186867714, AUC: 0.8818256536703138\n",
      "epoch: 19, loss: 41.15293064713478, AUC: 0.885748959778086\n",
      "epoch: 20, loss: 40.17878270149231, AUC: 0.8891007859454461\n",
      "epoch: 21, loss: 40.072235107421875, AUC: 0.8915536549031695\n",
      "epoch: 22, loss: 39.35182300209999, AUC: 0.8983086762212975\n",
      "epoch: 23, loss: 39.9772732257843, AUC: 0.9023282991729594\n",
      "epoch: 24, loss: 38.67496168613434, AUC: 0.9060974983305079\n",
      "epoch: 25, loss: 38.50077795982361, AUC: 0.9048132737453125\n",
      "epoch: 26, loss: 38.05814051628113, AUC: 0.9077027790620025\n",
      "epoch: 27, loss: 37.89734089374542, AUC: 0.910354702830431\n",
      "epoch: 28, loss: 37.88411536812782, AUC: 0.9117320336980532\n",
      "epoch: 29, loss: 37.32639876008034, AUC: 0.9142780089382031\n",
      "epoch: 30, loss: 37.09780219197273, AUC: 0.918291210766939\n",
      "epoch: 31, loss: 36.98028326034546, AUC: 0.919125956747316\n",
      "epoch: 32, loss: 36.768194139003754, AUC: 0.9236143216725741\n",
      "epoch: 33, loss: 36.282021313905716, AUC: 0.9254571839523296\n",
      "epoch: 34, loss: 36.335517197847366, AUC: 0.9263176144244105\n",
      "epoch: 35, loss: 36.21462786197662, AUC: 0.9295089125186212\n",
      "epoch: 36, loss: 35.9037549495697, AUC: 0.9303243951302205\n",
      "epoch: 37, loss: 35.93060255050659, AUC: 0.9318269378948991\n",
      "epoch: 38, loss: 35.50576442480087, AUC: 0.9329185287923152\n",
      "epoch: 39, loss: 35.87710106372833, AUC: 0.9334129552576154\n",
      "epoch: 40, loss: 35.477087527513504, AUC: 0.9341578055170288\n",
      "epoch: 41, loss: 35.26185482740402, AUC: 0.9362735655211384\n",
      "epoch: 42, loss: 34.876458168029785, AUC: 0.9353521343812606\n",
      "epoch: 43, loss: 35.622609585523605, AUC: 0.9364308830328247\n",
      "epoch: 44, loss: 35.212905794382095, AUC: 0.9377600554785022\n",
      "epoch: 45, loss: 35.06178516149521, AUC: 0.9400074485025941\n",
      "epoch: 46, loss: 34.81091567873955, AUC: 0.9401326603996507\n",
      "epoch: 47, loss: 35.141604483127594, AUC: 0.9398533415523707\n",
      "epoch: 48, loss: 34.8216515481472, AUC: 0.9410155648019727\n",
      "epoch: 49, loss: 34.93696194887161, AUC: 0.941192145682437\n",
      "epoch: 50, loss: 35.0761216878891, AUC: 0.9412467252273077\n",
      "epoch: 51, loss: 34.706730246543884, AUC: 0.9412338829814557\n",
      "epoch: 52, loss: 34.651477843523026, AUC: 0.9421328401910927\n",
      "epoch: 53, loss: 34.6254566013813, AUC: 0.9424603174603173\n",
      "epoch: 54, loss: 34.85024008154869, AUC: 0.9434909076899368\n",
      "epoch: 55, loss: 34.42020761966705, AUC: 0.9423896851081316\n",
      "epoch: 56, loss: 34.31432145833969, AUC: 0.9430189551548775\n",
      "epoch: 57, loss: 34.31775885820389, AUC: 0.9427685313607643\n",
      "epoch: 58, loss: 34.34498327970505, AUC: 0.9449260286638927\n",
      "epoch: 59, loss: 34.39535877108574, AUC: 0.9444508655673703\n",
      "epoch: 60, loss: 34.28082579374313, AUC: 0.9429097960651359\n",
      "epoch: 61, loss: 34.2909959256649, AUC: 0.9454589818667488\n",
      "epoch: 62, loss: 34.52919816970825, AUC: 0.9456708789233061\n",
      "epoch: 63, loss: 34.30640038847923, AUC: 0.9465024143422199\n",
      "epoch: 64, loss: 34.24321210384369, AUC: 0.9474944778342836\n",
      "epoch: 65, loss: 34.216218411922455, AUC: 0.9473692659372271\n",
      "epoch: 66, loss: 34.0870079100132, AUC: 0.9480916422663995\n",
      "epoch: 67, loss: 34.068428695201874, AUC: 0.9468009965582781\n",
      "epoch: 68, loss: 34.135213792324066, AUC: 0.9477256382596188\n",
      "epoch: 69, loss: 34.06786760687828, AUC: 0.9481622746185852\n",
      "epoch: 70, loss: 34.65565973520279, AUC: 0.9481430112498073\n",
      "epoch: 71, loss: 34.50452044606209, AUC: 0.9486727538912005\n",
      "epoch: 72, loss: 34.04331248998642, AUC: 0.9489199671238505\n",
      "epoch: 73, loss: 33.80363839864731, AUC: 0.9478380079108235\n",
      "epoch: 74, loss: 34.04193216562271, AUC: 0.9483581188678276\n",
      "epoch: 75, loss: 33.962124824523926, AUC: 0.948762649612164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = []\n",
    "for epoch in range(1000):\n",
    "    loss_total = 0\n",
    "    for data in train_loader:\n",
    "        d, p, w, true_label = data\n",
    "        d, p, w, true_label  = d.to(device), p.to(device), w.to(device), true_label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(d, p)\n",
    "        predicted_label = nn.Softmax(dim=1)(output)\n",
    "        loss = torch.mean(F.cross_entropy( predicted_label, true_label, reduce='none'))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total += loss.to('cpu').data.numpy()\n",
    "    pred_y, true_y = [], []\n",
    "    for data in val_loader:\n",
    "        d, p, w, true_label = data\n",
    "        d, p, w, true_label  = d.to(device), p.to(device), w.to(device), true_label.to(device)\n",
    "        output = model(d, p)\n",
    "        predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "        pred_y += predicted_label\n",
    "        true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "    score = roc_auc_score(true_y, pred_y)\n",
    "    if epoch > 10:\n",
    "        if np.mean(scores[-10:]) > score:\n",
    "            scores.append(score)\n",
    "            break\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\"epoch: {}, loss: {}, AUC: {}\".format(epoch, loss_total, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854820309873912\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in train_loader:\n",
    "    d, p, w, true_label = data\n",
    "    d, p, w, true_label  = d.to(device), p.to(device), w.to(device), true_label.to(device)\n",
    "\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486823855755895\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in val_loader:\n",
    "    d, p, w, true_label = data\n",
    "    d, p, w, true_label  = d.to(device), p.to(device), w.to(device), true_label.to(device)\n",
    "\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934037585082387\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in test_loader:\n",
    "    d, p, true_label = data\n",
    "    d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c8a2ce01946fc569c1a09c9b4b77c6cb39ea00399395c0b1868d5ff55caf205"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
