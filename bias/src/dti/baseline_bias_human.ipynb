{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdMolDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rdic = ['A','I','L','V','F','W','Y','N','C','Q','M','S','T','D','E','R','H','K','G','P','O','U','X','B','Z']\n",
    "seq_dic = {w: i+1 for i, w in enumerate(seq_rdic)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeSeq(seq, seq_dic):\n",
    "    if pd.isnull(seq):\n",
    "        return [0]\n",
    "    else:\n",
    "        return [seq_dic[aa] for aa in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_seq(x, max_len=2500):\n",
    "    if len(x) == 0:\n",
    "        return x\n",
    "    elif len(x) >= max_len:\n",
    "        return x[:max_len]\n",
    "    else:\n",
    "        return x + [0]*(max_len-len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(dti_dir, prot_len=2500, drug_len=2048):\n",
    "\n",
    "    protein_col = \"protein\"\n",
    "    drug_col = \"compound\"\n",
    "    label_col = \"label\"\n",
    "    col_names = [protein_col, drug_col, label_col]\n",
    "    \n",
    "    dti_df = pd.read_csv(dti_dir, header=0)\n",
    "\n",
    "    dti_df[protein_col] = dti_df[protein_col].map(lambda a: encodeSeq(a, seq_dic))\n",
    "    \n",
    "    drug_feature = np.stack(dti_df[drug_col].map(\n",
    "        lambda sm: AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(sm),2,nBits=drug_len)\n",
    "    ))\n",
    "    \n",
    "    protein_feature = np.stack(dti_df[protein_col].map(padding_seq))\n",
    "    label = dti_df[label_col].values\n",
    "    \n",
    "    print(\"\\tPositive data : %d\" %(sum(dti_df[label_col])))\n",
    "    print(\"\\tNegative data : %d\" %(dti_df.shape[0] - sum(dti_df[label_col])))\n",
    "    \n",
    "    return {\"protein_feature\": protein_feature, \n",
    "            \"drug_feature\": drug_feature, \n",
    "            \"label\": label,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:28] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPositive data : 1876\n",
      "\tNegative data : 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:44:32] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPositive data : 331\n",
      "\tNegative data : 341\n"
     ]
    }
   ],
   "source": [
    "train_datas = parse_data(\"../../data/maked/bias/train_human.csv\")\n",
    "test_datas = parse_data(\"../../data/maked/bias/test_human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_drug = nn.Linear(2048, 64)\n",
    "        \n",
    "        self.conv1D = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=128, stride=1, padding=0)\n",
    "        self.batch = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, 128)\n",
    "        self.fc_interaction = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, drug, protein):\n",
    "        compound_vector = self.fc_drug(drug)\n",
    "        compound_vector = torch.relu(compound_vector)\n",
    "\n",
    "        protein = torch.unsqueeze(protein, 1)\n",
    "        protein_vector = self.conv1D(protein)\n",
    "        protein_vector = self.batch(protein_vector)\n",
    "        protein_vector = torch.relu(protein_vector)\n",
    "        \n",
    "        protein_vector = F.max_pool1d(protein_vector, kernel_size=2373)\n",
    "        protein_vector = torch.squeeze(protein_vector, 2)\n",
    "        \n",
    "        cat_vector = torch.cat((compound_vector, protein_vector), 1)\n",
    "        \n",
    "        for j in range(2):\n",
    "            cat_vector = torch.relu(self.fc_out(cat_vector))\n",
    "        out = self.fc_interaction(cat_vector)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses GPU...\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drug_dataset = torch.FloatTensor(train_datas[\"drug_feature\"])\n",
    "train_protein_dataset = torch.FloatTensor(train_datas[\"protein_feature\"])\n",
    "train_target_dataset = torch.LongTensor(train_datas[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drug_dataset = torch.FloatTensor(test_datas[\"drug_feature\"])\n",
    "test_protein_dataset = torch.FloatTensor(test_datas[\"protein_feature\"])\n",
    "test_target_dataset = torch.LongTensor(test_datas[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_drug_dataset, train_protein_dataset, train_target_dataset)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_drug_dataset, test_protein_dataset, test_target_dataset)\n",
    "\n",
    "N = len(train_dataset)\n",
    "train_size = int(0.8 * N)\n",
    "val_size = N - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 58.47306215763092, AUC: 0.5752908171470437\n",
      "epoch: 1, loss: 58.173059940338135, AUC: 0.602817933277344\n",
      "epoch: 2, loss: 58.01193618774414, AUC: 0.6202580276253953\n",
      "epoch: 3, loss: 57.61207467317581, AUC: 0.65713060414917\n",
      "epoch: 4, loss: 57.278115808963776, AUC: 0.6744634848024588\n",
      "epoch: 5, loss: 56.851521611213684, AUC: 0.6897861086789486\n",
      "epoch: 6, loss: 55.882786989212036, AUC: 0.691885710201383\n",
      "epoch: 7, loss: 55.11020576953888, AUC: 0.6998150563765345\n",
      "epoch: 8, loss: 53.79955035448074, AUC: 0.7301341958079445\n",
      "epoch: 9, loss: 52.53967607021332, AUC: 0.7333506066508229\n",
      "epoch: 10, loss: 51.19662469625473, AUC: 0.7599038650536962\n",
      "epoch: 11, loss: 49.8689700961113, AUC: 0.7684898951092687\n",
      "epoch: 12, loss: 47.85645377635956, AUC: 0.7915765773814842\n",
      "epoch: 13, loss: 45.79874449968338, AUC: 0.8145203080606829\n",
      "epoch: 14, loss: 44.47428673505783, AUC: 0.8249111019780927\n",
      "epoch: 15, loss: 42.28650778532028, AUC: 0.8296195700730838\n",
      "epoch: 16, loss: 40.795512080192566, AUC: 0.8376337937565892\n",
      "epoch: 17, loss: 38.828978538513184, AUC: 0.8423869342243983\n",
      "epoch: 18, loss: 37.78770104050636, AUC: 0.8395457713131889\n",
      "epoch: 19, loss: 36.911440044641495, AUC: 0.8451387523899718\n",
      "epoch: 20, loss: 35.88377261161804, AUC: 0.8427264442578132\n",
      "epoch: 21, loss: 35.247757226228714, AUC: 0.8493111520111503\n",
      "epoch: 22, loss: 34.12529373168945, AUC: 0.8552257741722209\n",
      "epoch: 23, loss: 33.74359834194183, AUC: 0.8570126690849311\n",
      "epoch: 24, loss: 33.33189344406128, AUC: 0.8531574433107589\n",
      "epoch: 25, loss: 33.00382289290428, AUC: 0.8593177635223272\n",
      "epoch: 26, loss: 32.54441639780998, AUC: 0.8585225952861713\n",
      "epoch: 27, loss: 32.64263468980789, AUC: 0.8582456265747012\n",
      "epoch: 28, loss: 32.31776311993599, AUC: 0.8617032682307953\n",
      "epoch: 29, loss: 32.33581790328026, AUC: 0.8611582652824187\n",
      "epoch: 30, loss: 31.9040724337101, AUC: 0.859103336132802\n",
      "epoch: 31, loss: 31.7212011218071, AUC: 0.8671622321891249\n",
      "epoch: 32, loss: 31.632878571748734, AUC: 0.8694315887282669\n",
      "epoch: 33, loss: 31.691187977790833, AUC: 0.8690965459321338\n",
      "epoch: 34, loss: 31.531645894050598, AUC: 0.8660945624787806\n",
      "epoch: 35, loss: 31.383423000574112, AUC: 0.8689580615763987\n",
      "epoch: 36, loss: 31.515391379594803, AUC: 0.874184729196076\n",
      "epoch: 37, loss: 31.553460359573364, AUC: 0.8763602737523006\n",
      "epoch: 38, loss: 31.31601110100746, AUC: 0.872652466808427\n",
      "epoch: 39, loss: 31.140890896320343, AUC: 0.8760788378035488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = []\n",
    "for epoch in range(1000):\n",
    "    loss_total = 0\n",
    "    for data in train_loader:\n",
    "        d, p, true_label = data\n",
    "        d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(d, p)\n",
    "        predicted_label = nn.Softmax(dim=1)(output)\n",
    "        loss = F.cross_entropy( predicted_label, true_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total += loss.to('cpu').data.numpy()\n",
    "    pred_y, true_y = [], []\n",
    "    for data in val_loader:\n",
    "        d, p, true_label = data\n",
    "        d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "        output = model(d, p)\n",
    "        predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "        pred_y += predicted_label\n",
    "        true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "    score = roc_auc_score(true_y, pred_y)\n",
    "    if epoch > 10:\n",
    "        if np.mean(scores[-10:]) > score:\n",
    "            scores.append(score)\n",
    "            break\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\"epoch: {}, loss: {}, AUC: {}\".format(epoch, loss_total, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808477467642807\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in train_loader:\n",
    "    d, p, true_label = data\n",
    "    d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8690652752711614\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in val_loader:\n",
    "    d, p, true_label = data\n",
    "    d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8690008948268377\n"
     ]
    }
   ],
   "source": [
    "pred_y, true_y = [], []\n",
    "for data in test_loader:\n",
    "    d, p, true_label = data\n",
    "    d, p, true_label  = d.to(device), p.to(device), true_label.to(device)\n",
    "    output = model(d, p)\n",
    "    predicted_label = nn.Softmax(dim=1)(output)[:,1].to('cpu').data.numpy().tolist()\n",
    "    pred_y += predicted_label\n",
    "    true_y += true_label.to('cpu').data.numpy().tolist()\n",
    "print(roc_auc_score(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c8a2ce01946fc569c1a09c9b4b77c6cb39ea00399395c0b1868d5ff55caf205"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
